# ğŸš€ Golden Path Strands Framework

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![AWS Strands](https://img.shields.io/badge/AWS-Strands-orange.svg)](https://github.com/strands-agents/sdk-python)
[![OpenTelemetry](https://img.shields.io/badge/OpenTelemetry-Enabled-green.svg)](https://opentelemetry.io/)

> **Transform expensive AI agent explorations into efficient, production-ready systems through systematic optimization**

Golden Path Strands is a self-improving AI agent framework that discovers optimal decision paths through complex multi-step processes, evaluates them using ensemble LLM judging, and distills successful patterns into specialized models. Built on AWS Strands, it reduces costs by 98% and latency by 95% while improving success rates.

## ğŸŒŸ Key Features

- **ğŸ” Exploration Logging**: Comprehensive decision path tracking with full context capture
- **âš–ï¸ Ensemble Evaluation**: Multi-model LLM-as-judge system with voting mechanisms
- **ğŸ“Š Pattern Distillation**: Automatic JSONL dataset creation from successful paths
- **ğŸ¯ Model Fine-tuning**: Integrated workflow for continuous improvement
- **ğŸ“ˆ Production Monitoring**: OpenTelemetry integration with real-time metrics
- **ğŸ”„ Multi-Provider Support**: Works with OpenAI, Ollama, Bedrock, and more
- **ğŸ›¡ï¸ Security First**: Input validation and sandboxed execution
- **ğŸ“ Comprehensive Logging**: Structured logs for debugging and analysis

## ğŸ“‹ Table of Contents

- [Quick Start](#-quick-start)
- [Installation](#-installation)
- [Core Concepts](#-core-concepts)
- [Architecture](#ï¸-architecture)
- [Usage Examples](#-usage-examples)
- [Configuration](#ï¸-configuration)
- [Monitoring & Logging](#-monitoring--logging)
- [API Reference](#-api-reference)
- [Contributing](#-contributing)
- [License](#-license)

## ğŸš€ Quick Start

```bash
# Clone the repository
git clone https://github.com/JohnJBoren/golden-path-strands.git
cd golden-path-strands

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
cp .env.example .env
# Edit .env with your API keys

# Run the demo
python examples/quick_start.py
```

## ğŸ’» Installation

### Prerequisites

- Python 3.8+
- Docker (optional, for containerized deployment)
- Ollama (optional, for local model support)

### Standard Installation

```bash
pip install golden-path-strands
```

### Development Installation

```bash
git clone https://github.com/JohnJBoren/golden-path-strands.git
cd golden-path-strands
pip install -e ".[dev]"
```

### Docker Installation

```bash
docker pull johnjboren/golden-path-strands:latest
docker run -p 8080:8080 johnjboren/golden-path-strands
```

## ğŸ§  Core Concepts

### The Golden Path Methodology

The Golden Path methodology systematically discovers optimal decision paths through:

1. **Exploration**: Use powerful models to explore decision spaces
2. **Evaluation**: Apply ensemble judging to identify successful paths
3. **Extraction**: Convert patterns into structured training data
4. **Embedding**: Train specialized models on golden paths
5. **Evolution**: Continuously improve through feedback loops

### Key Components

- **Exploration Logger**: Tracks every decision, tool use, and reasoning step
- **LLM Judge Evaluator**: Multi-model ensemble evaluation system
- **Voting System**: Advanced voting mechanisms (majority, weighted, ranked choice)
- **Dataset Creator**: Automatic JSONL generation from successful paths
- **Fine-tuning Workflow**: Orchestrated model training pipeline

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 User Interface                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              Golden Path Orchestrator            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Exploration â”‚  Evaluation  â”‚   Refinement       â”‚
â”‚   Agents    â”‚   Ensemble   â”‚    Pipeline        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚               Strands Core Engine                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     Model Providers (OpenAI/Ollama/Bedrock)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“š Usage Examples

### Basic Usage

```python
from golden_path import GoldenPathStrands

# Initialize the framework
gps = GoldenPathStrands()

# Define exploration tasks
tasks = [
    "Create a data analysis pipeline",
    "Design a microservices architecture",
    "Optimize database queries"
]

# Run the complete pipeline
results = await gps.run_complete_pipeline(tasks)
print(f"Discovered {results['discovered_paths']} golden paths")
print(f"Average success score: {results['average_score']:.2f}")
```

### Advanced Configuration

```python
from golden_path import GoldenPathStrands, ModelProviderConfig

config = {
    'judge_models': [
        {'type': 'ollama', 'host': 'http://localhost:11434', 'model_id': 'llama3'},
        {'type': 'openai', 'model_id': 'gpt-4'},
        {'type': 'bedrock', 'model_id': 'claude-sonnet'}
    ],
    'min_success_score': 0.8,
    'evaluation_threshold': 0.85
}

gps = GoldenPathStrands(config=config)
```

### Monitoring Integration

```python
from golden_path.monitoring import MetricsCollector

# Enable metrics collection
metrics = MetricsCollector()
gps = GoldenPathStrands(metrics_collector=metrics)

# Access metrics
print(metrics.get_summary())
```

## âš™ï¸ Configuration

### Environment Variables

```bash
# API Keys
OPENAI_API_KEY=your-openai-key
AWS_ACCESS_KEY_ID=your-aws-key
AWS_SECRET_ACCESS_KEY=your-aws-secret

# Ollama Configuration
OLLAMA_HOST=http://localhost:11434

# Monitoring
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
OTEL_SERVICE_NAME=golden-path-strands

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json
```

### Configuration File (config.yaml)

```yaml
golden_path:
  exploration:
    model: gpt-4-turbo
    sample_size: 10000
    logging_level: detailed
    
  evaluation:
    judges:
      - model: gpt-4
        weight: 0.3
      - model: claude-3.5-sonnet
        weight: 0.3
      - model: gemini-pro
        weight: 0.2
    consensus_threshold: 0.8
    
  training:
    base_model: mistral-7b-instruct
    learning_rate: 5e-5
    batch_size: 32
    epochs: 3
    
  deployment:
    confidence_threshold: 0.85
    fallback_model: gpt-4-turbo
    monitoring_enabled: true
```

## ğŸ“Š Monitoring & Logging

### Structured Logging

All agent calls, decisions, and evaluations are logged in structured JSON format:

```json
{
  "timestamp": "2025-08-31T10:30:45Z",
  "session_id": "golden_path_001",
  "event_type": "decision_point",
  "agent_id": "explorer_01",
  "decision": {
    "input": "Optimize database query",
    "action": "analyze_query_plan",
    "reasoning": "Identifying bottlenecks in execution plan",
    "confidence": 0.92
  },
  "metrics": {
    "tokens_used": 450,
    "latency_ms": 234,
    "cost": 0.0045
  }
}
```

### Metrics Dashboard

Access real-time metrics at `http://localhost:8080/metrics`:

- Path discovery rate
- Success scores distribution
- Token usage and costs
- Model performance comparison
- Error rates and latencies

### OpenTelemetry Integration

```python
from golden_path.monitoring import setup_telemetry

# Configure OpenTelemetry
setup_telemetry(
    service_name="golden-path-production",
    endpoint="http://your-otel-collector:4317"
)
```

## ğŸ“– API Reference

### Core Classes

#### `GoldenPathStrands`

Main orchestrator class for the Golden Path framework.

```python
class GoldenPathStrands:
    def __init__(self, config: Dict = None)
    async def discover_golden_paths(self, tasks: List[str], iterations: int = 3)
    async def create_training_dataset(self, paths: List[Dict])
    async def run_complete_pipeline(self, tasks: List[str])
```

#### `ExplorationLogger`

Comprehensive logging system for path discovery.

```python
class ExplorationLogger:
    def log_decision_point(self, agent_result, context: Dict)
    def mark_path_successful(self, score: float, metadata: Dict)
    def get_successful_paths(self) -> List[Dict]
```

#### `LLMJudgeEvaluator`

Ensemble evaluation system using multiple LLM judges.

```python
class LLMJudgeEvaluator:
    async def evaluate_response(self, query: str, response: str, tools: List[str])
    def get_consensus_score(self, evaluations: List[Dict]) -> float
```

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

### Development Setup

```bash
# Clone the repo
git clone https://github.com/JohnJBoren/golden-path-strands.git
cd golden-path-strands

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install development dependencies
pip install -e ".[dev]"

# Run tests
pytest tests/

# Run linting
flake8 src/
black src/
```

## ğŸ”’ Security

See [SECURITY.md](SECURITY.md) for our security policy and how to report vulnerabilities.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- AWS Strands team for the excellent agent framework
- OpenAI, Anthropic, and the open-source community
- Contributors and early adopters

## ğŸ“¬ Contact

- GitHub Issues: [Report a bug](https://github.com/JohnJBoren/golden-path-strands/issues)
- Discussions: [Ask questions](https://github.com/JohnJBoren/golden-path-strands/discussions)

---

<p align="center">
  Built with â¤ï¸ for the AI community
</p>